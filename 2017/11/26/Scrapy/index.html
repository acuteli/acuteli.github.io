<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="scrapy," />










<meta name="description" content="爬虫1234567url模块综合url和lib的一个包 第一部分是协议：http,https,ftp,file,ed2k…第二部分是存放资源的服务器的域名系统或IP地址（有时候要包含端口号，各种传输协议都有默认的端口，如http的默认端口是80）第三部分是资源的具体地址，如目录或者文件名等 python中操作文件步骤">
<meta name="keywords" content="scrapy">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy笔记">
<meta property="og:url" content="http://yoursite.com/2017/11/26/Scrapy/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="爬虫1234567url模块综合url和lib的一个包 第一部分是协议：http,https,ftp,file,ed2k…第二部分是存放资源的服务器的域名系统或IP地址（有时候要包含端口号，各种传输协议都有默认的端口，如http的默认端口是80）第三部分是资源的具体地址，如目录或者文件名等 python中操作文件步骤">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2017-11-27T03:23:20.171Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scrapy笔记">
<meta name="twitter:description" content="爬虫1234567url模块综合url和lib的一个包 第一部分是协议：http,https,ftp,file,ed2k…第二部分是存放资源的服务器的域名系统或IP地址（有时候要包含端口号，各种传输协议都有默认的端口，如http的默认端口是80）第三部分是资源的具体地址，如目录或者文件名等 python中操作文件步骤">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.3',
    sidebar: {"position":"right","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/11/26/Scrapy/"/>





  <title>Scrapy笔记 | Hexo</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            日程表
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/26/Scrapy/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="李丛丛">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Scrapy笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-26T16:17:37+08:00">
                2017-11-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/base/" itemprop="url" rel="index">
                    <span itemprop="name">base</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">url模块综合url和lib的一个包</span><br><span class="line"> </span><br><span class="line">第一部分是协议：http,https,ftp,file,ed2k…</span><br><span class="line"></span><br><span class="line">第二部分是存放资源的服务器的域名系统或IP地址（有时候要包含端口号，各种传输协议都有默认的端口，如http的默认端口是80）</span><br><span class="line"></span><br><span class="line">第三部分是资源的具体地址，如目录或者文件名等</span><br></pre></td></tr></table></figure>
<h2 id="python中操作文件步骤"><a href="#python中操作文件步骤" class="headerlink" title="python中操作文件步骤"></a>python中操作文件步骤</h2><a id="more"></a>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">1. 打开文件，得到文件句柄并赋值给一个变量 </span><br><span class="line"> f.open(&apos;a.txt&apos;,&apos;w&apos;,encoding=&apos;utf-8&apos;)</span><br><span class="line">2. 通过句柄对文件进行操作</span><br><span class="line">  data = f.read()</span><br><span class="line">3. 关闭文件</span><br><span class="line"> f.close()</span><br></pre></td></tr></table></figure>
<h3 id="计算机操作系统分为-硬件-操作系统-应用程序"><a href="#计算机操作系统分为-硬件-操作系统-应用程序" class="headerlink" title="计算机操作系统分为:硬件,操作系统,应用程序"></a>计算机操作系统分为:硬件,操作系统,应用程序</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">工作过程:</span><br><span class="line">由应用程序向操作系统发起系统调用open();</span><br><span class="line">操作系统打开文件,返回文件句柄给应用程序;</span><br><span class="line">应用程序赋值给变量</span><br></pre></td></tr></table></figure>
<blockquote>
<p>selenium自动下拉,模仿按键精灵</p>
<p>MVC 模型视图控制器</p>
</blockquote>
<h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HTTP协议是一个无状态的协议，同一个客户端的这次请求和上次请求是没有对应关系。</span><br><span class="line"></span><br><span class="line">MIME:设定某种扩展名的文件用一种应用程序来打开的方式类型，当该扩展名文件被访问的时候，浏览器会自动使用指定应用程序来打开</span><br></pre></td></tr></table></figure>
<h3 id="HTTP工作流程"><a href="#HTTP工作流程" class="headerlink" title="HTTP工作流程:"></a>HTTP工作流程:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.客户机和服务器建立连接,单机超链接,http开始工作</span><br><span class="line">2.建立连接后,客户机发送请求给服务器,发送格式为:</span><br><span class="line">	统一资源标识符(URL),</span><br><span class="line">	协议版本号,</span><br><span class="line">	MIME:请求修饰符,客户机信息</span><br><span class="line">3.服务器接到请求,回应响应信息,返回格式为:</span><br><span class="line">	信息协议版本号,</span><br><span class="line">	成功或错误码,</span><br><span class="line">	MIME:服务器信息,实体信息,可能内容</span><br><span class="line">4.客户机接到服务器返回信息通过浏览器显示在用户显示屏,客户机与服务器断开连接</span><br></pre></td></tr></table></figure>
<h3 id="计算10天前是几号"><a href="#计算10天前是几号" class="headerlink" title="计算10天前是几号"></a>计算10天前是几号</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import datetime</span><br><span class="line">from datetime import timedelta</span><br><span class="line">(datetime.datetime.now() - datetime.timedelta(days = 10)).strftime(&quot;%Y-%m-%d&quot;)</span><br></pre></td></tr></table></figure>
<h3 id="网络爬虫的原理-网络请求-抓取结构化数据-数据存储"><a href="#网络爬虫的原理-网络请求-抓取结构化数据-数据存储" class="headerlink" title="网络爬虫的原理 网络请求 抓取结构化数据 数据存储"></a>网络爬虫的原理 网络请求 抓取结构化数据 数据存储</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.打开浏览器,输入URL,打开源网页</span><br><span class="line">2.选取我们想要的内容</span><br><span class="line">3.存入到硬盘中</span><br></pre></td></tr></table></figure>
<h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">随机删除元素:popitem()</span><br></pre></td></tr></table></figure>
<h3 id="Apache和Tomcat比较"><a href="#Apache和Tomcat比较" class="headerlink" title="Apache和Tomcat比较"></a>Apache和Tomcat比较</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">相同:</span><br><span class="line">	都是Apache组织开发的</span><br><span class="line">	都有HTTP服务功能</span><br><span class="line">	都是免费的</span><br><span class="line">不同:</span><br><span class="line">	Apache专门提供HTTP服务,以及虚拟主机,URL转发,而Tomcat是Apache组织在符合JAvaEE的标准下开发的一个JSP服务器</span><br><span class="line">	Apache是一个Web服务器环境程序,不过只支持静态网页,对于动态网页需要JSP解释器来执行动态网页</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Nginx是一个高性能的HTTP和反向代理服务器,十分轻量级的HTTP服务器</p>
</blockquote>
<h3 id="网页爬虫的基本工作原理"><a href="#网页爬虫的基本工作原理" class="headerlink" title="网页爬虫的基本工作原理"></a>网页爬虫的基本工作原理</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">选取种子URl</span><br><span class="line">将代抓取URl放入代抓取URL队列</span><br><span class="line">从代抓取队列中抓取URL,解析DNS,并且得到主机ip,并将URL对应的网页下载下来,存储到已经下载的网页库中,将已经住区url存入已经抓取的URL队列</span><br></pre></td></tr></table></figure>
<h3 id="用于转化header"><a href="#用于转化header" class="headerlink" title="用于转化header"></a>用于转化header</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ctrl+r转换头部为字典:</span><br><span class="line">(.*): (.*)  |    &amp;</span><br><span class="line">&quot;$1&quot;: &quot;$2&quot;, |    \n</span><br></pre></td></tr></table></figure>
<h3 id="积累"><a href="#积累" class="headerlink" title="积累"></a>积累</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">1.json.dumps:将字典转化为json</span><br><span class="line">  json.loads:将json转化为字典</span><br><span class="line"></span><br><span class="line">2.没有验证码情况下模拟豆瓣登陆使用首页的地址和header头</span><br><span class="line"></span><br><span class="line">3.调用函数:</span><br><span class="line">  if __name__ == &apos;__mian__&apos;:</span><br><span class="line">        login()</span><br><span class="line"></span><br><span class="line">4.request.urlretrieve(): 下载 p1:下载地址 p2:文件保存路径</span><br><span class="line">  re.S换行符号</span><br><span class="line">  下载图片: from urllib import request</span><br><span class="line">      fname = pic.split(&apos;/&apos;)[-1]  切割后去取最后一位;</span><br><span class="line">      request.urlretrieve(pic,&apos;./images/&apos; + fname)  下载图片;</span><br><span class="line"></span><br><span class="line">5.session:存在服务器端基于cookie实现 存放形式:数据库,文件,内存</span><br><span class="line">  session多台服务器的共享: 单独建立缓存服务器,多台服务器共同使用</span><br><span class="line">  cookie:存在客户端浏览器的用户信息</span><br></pre></td></tr></table></figure>
<h3 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from http import cookiejar:导入cookie管理器,存储cookie</span><br><span class="line">cookie = cookiejar.CookieJar:做个cookie对象</span><br><span class="line">cookie_hander = request.HTTPcookieProcessor(cookie) :可以管理cookie的管理器</span><br><span class="line">opener = request.build_opener(cookie_hander)</span><br></pre></td></tr></table></figure>
<h2 id="第四天-正则表达式"><a href="#第四天-正则表达式" class="headerlink" title="第四天  正则表达式"></a>第四天  正则表达式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">1.电话 邮箱 账号 密码 IP地址 校验</span><br><span class="line"></span><br><span class="line">2.目标字符匹配</span><br><span class="line">  \d : 匹配数字(0-9),匹配一次            |  \D:非\d</span><br><span class="line">  \w : 匹配数字 字母 下划线(包括大写)     |  \W:非\w</span><br><span class="line">  \s : 匹配一个空格                      |  \S:非\s</span><br><span class="line"></span><br><span class="line">  . : 匹配任意字符</span><br><span class="line">  \ : 转义字符 (两个斜杠时,在匹配项的引号前加r转义,载原字符串也加r)</span><br><span class="line">  + : 前面的匹配项重复1-N次</span><br><span class="line">  * : 前面字符,重复0-N次</span><br><span class="line">  ? : 前面字符,重复0次或1次</span><br><span class="line"></span><br><span class="line">  &#123;n,m&#125;: 重复n-m次</span><br><span class="line">  [0-9a-zA-Z,#]: 匹配0-9a-zA-Z逗号#号,匹配任意一个</span><br><span class="line">  [0-9a-zA-Z,#]+: 匹配0-9a-zA-Z逗号#号,匹配符合全部的,到不合适的结束</span><br><span class="line">  [^]:非[]号中的</span><br><span class="line">  ():分组概念</span><br><span class="line">     group(0)</span><br><span class="line">     group(1)</span><br><span class="line">     group(2)</span><br><span class="line">  ^ : 以规则开始</span><br><span class="line">  $ : 以规则结束</span><br><span class="line"></span><br><span class="line">  注意:</span><br><span class="line">    1. . *匹配默认是贪婪模式</span><br><span class="line"></span><br><span class="line">  re.compile(): 编译规则,参数就是规则</span><br><span class="line">  match方法:从开始位置查找,一次匹配</span><br><span class="line">  search方法:检索目标字符串,返回第一次出现符合规则的字符串;为匹配到返回none;</span><br><span class="line">  findall方法:匹配全部,返回结果是列表</span><br><span class="line">  finditer方法:迭代器 只能迭代一次</span><br><span class="line">  res.group()   取出匹配到的</span><br></pre></td></tr></table></figure>
<h2 id="day5-反反爬"><a href="#day5-反反爬" class="headerlink" title="day5:反反爬"></a>day5:反反爬</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1.headers</span><br><span class="line">2.cookie</span><br><span class="line">3.USER_AGENT</span><br><span class="line">4.proxy 代理</span><br><span class="line">    1.网上获取免费代理</span><br><span class="line">        西刺:速度越快,时间越短</span><br><span class="line">	2.购买IP</span><br><span class="line">5.时间间隔 timeout timesleep</span><br><span class="line">6.并发:多线程</span><br><span class="line">    seleinum -----&gt;  phanomjs</span><br><span class="line"></span><br><span class="line">反爬虫手段:</span><br><span class="line">    urllib User-Agent;  timeout timesleep; 验证码; Pathtomjs selenium;</span><br><span class="line"></span><br><span class="line">7.print(&apos;crawing page %s&apos; % base_url) #打印获取页数路径</span><br><span class="line">  f.readlines() : 读取每一行</span><br></pre></td></tr></table></figure>
<h3 id="周一-如何解析页面-提取数据"><a href="#周一-如何解析页面-提取数据" class="headerlink" title="周一: 如何解析页面,提取数据"></a>周一: 如何解析页面,提取数据</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">requests:安装 pip install requests</span><br><span class="line">  优点:有长链接,保存链接,节省资源 封装简单化</span><br><span class="line">  缺点:第三方封装模块,发生问题概率大于url</span><br><span class="line"></span><br><span class="line">  jsonpath:构建规则,专门提取json数据  参数1 数据参数:字典 ;参数2 匹配规则</span><br><span class="line">       jsonpath.jsonpath()</span><br><span class="line">       $:从根节点开始匹配</span><br><span class="line">       $ ..: 不管位置,选择所有适合条件的</span><br><span class="line">       *:匹配所有元素节点</span><br><span class="line">  xpath: xml: 不经常使用</span><br><span class="line">       path:转化html为节点,提取数据</span><br><span class="line">       .:当前节点</span><br><span class="line">  bs4:基于正则封装</span><br><span class="line"></span><br><span class="line">requests 模块:</span><br><span class="line">get请求:</span><br><span class="line">    params=&#123;&apos;wd&apos;,&apos;ip&apos;&#125;  传入类型为字典,放在路径后面</span><br><span class="line">    response.encoding(&apos;gbk&apos;) 转换编码格式</span><br><span class="line">post请求:</span><br><span class="line">    登陆页面 加header  加data</span><br><span class="line"></span><br><span class="line">cookie的存储:</span><br><span class="line">        建立会话</span><br><span class="line">        sess = resuests.session()</span><br><span class="line">        sess.get()   #发送get请求</span><br><span class="line">        sess.post()  #发送post请求</span><br><span class="line"></span><br><span class="line">如何加代理:</span><br><span class="line">proxy = &#123;</span><br><span class="line">    &apos;http&apos; : &apos;http://ip:端口号&apos;,</span><br><span class="line">    &apos;https&apos; : &apos;https://ip:端口号&apos;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>##周二:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">BeautifulSoup4:</span><br><span class="line">直接获取，获取第一个</span><br><span class="line">	print(html.p.attrs) ;获取p的所有属性，</span><br><span class="line">	print（html.p[&apos;class&apos;]）;获取单个属性</span><br><span class="line">	</span><br><span class="line">	html.p.find_all(&apos;b&apos;); 获取所有p标签下的b标签</span><br><span class="line">	html.find_all(&apos;p&apos;,&apos;b&apos;);可以传入多个标记</span><br><span class="line">	</span><br><span class="line">	html.find_all(id=&apos;link1&apos;);根据id获取</span><br><span class="line">	html.find_all(&apos;p&apos;,attrs=&#123;&apos;class&apos;:&apos;title&apos;&#125;);根据属性过滤标记，attrs,需要传入字典</span><br><span class="line"></span><br><span class="line">CSS选择器：</span><br><span class="line"></span><br><span class="line">	html.select(&apos;p.title&apos;)；类过滤class</span><br><span class="line">	html.select(&apos;a#link1&apos;); id过滤 id</span><br><span class="line">	html.select(&apos;&apos;)</span><br><span class="line">	html.select(&apos;p[class=&quot;title&quot;]&apos;); 单个查询；</span><br><span class="line">	</span><br><span class="line">	html.select(&apos;p[class*=&quot;&quot;]&apos;);模糊查询；</span><br><span class="line">	html.select(&apos;p[class=&quot;&quot;]&apos;);模糊查询；</span><br><span class="line">	html.select(&apos;p[class*=&quot;&quot;]&apos;);模糊查询；</span><br><span class="line"></span><br><span class="line">content ;取内容和标签；</span><br><span class="line"></span><br><span class="line">解析数据:</span><br><span class="line">    xpath; BeautifulSoup;lxml;CSS选择器</span><br></pre></td></tr></table></figure></p>
<p>##周三: 并发量:提高采集效率<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">多进程:cpu资源分配的最小单位</span><br><span class="line">	  适合计算密集型应用 cpu密集型(对cpu消耗非常大)</span><br><span class="line">	</span><br><span class="line">线程: cpu调度的最小单位</span><br><span class="line">	  线程之间调度由操作系统来决定</span><br><span class="line">	  适合IO(输入输出 input output) 密集型应用</span><br><span class="line">	  爬虫主要就是网络IO(request:输出 response:输入)</span><br><span class="line">	</span><br><span class="line">协程:轻量级线程,单进程,单线程,写程序(代码)来调度(切换)程序</span><br><span class="line">	</span><br><span class="line">分布式:数据量非常大(PB),把程序部署到多台机器上</span><br><span class="line">	  优点:并发量大</span><br><span class="line">	  缺点:成本较高;网络带宽限制分布式爬虫</span><br><span class="line"></span><br><span class="line">#线程模块:</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">    线程函数传入参数</span><br><span class="line">    t1 = threading.Thread(target=foo3,args=(1,))</span><br><span class="line"></span><br><span class="line">    join();确保运行完毕,继续运行进程,阻塞进程,串行</span><br><span class="line">        1.join方法主要是阻塞住进程(无法执行join语句后的语句),专注多进程</span><br><span class="line">        2.多线程情况下,前一个结束才执行后面一个</span><br><span class="line">        3.无参数,则等待该线程结束,才开始执行下一个线程的join</span><br><span class="line">        4.</span><br><span class="line">    t.is_alive();判断线程存活状态 ,若存活返回true,若不存活返回flase</span><br><span class="line"></span><br><span class="line">    栈: 先进后出,后进先出 递归</span><br><span class="line">    队列:先进先出,后进后出,线程安全,操作后锁定</span><br><span class="line">    列表;非线程安全的</span><br><span class="line">    super(Crawl,self ) 调用父类初始化方法;</span><br><span class="line"></span><br><span class="line">#队列模块:</span><br><span class="line">import queue</span><br><span class="line">    q = queue.Queue()  队列;</span><br><span class="line">    q.put(1)  放数据;</span><br><span class="line">    q.get(1)  取数据;</span><br><span class="line">    q.get(timeout) 设置超时时间;</span><br><span class="line">    q.qsize  求出队列长度;</span><br><span class="line"></span><br><span class="line">创建队列 初始化在def __init__()</span><br></pre></td></tr></table></figure></p>
<p>###周四:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">反爬虫手段:</span><br><span class="line">    遇到ajax,请求 抓包工具,找到数据接口(最理想的)</span><br><span class="line">    自动化测试工具 配合 浏览器来完成模拟用户真实操作自动化</span><br><span class="line">把Selenium和PhantomJS结合在一起,是一个强大的网络爬虫,可以处理JavaScrip,Cookie,headers,以及我们真实用户实现的任何操作</span><br><span class="line"></span><br><span class="line">Selenium: 可以按照指定的命令自动操作,可以按照指令自行加载页面,进行截屏</span><br><span class="line">          Selenium自己不带浏览器,不支持浏览器功能,需要与第三方浏览器结合在一起才能使用</span><br><span class="line">          但我们有时候需要内嵌代码执行,</span><br><span class="line"></span><br><span class="line">PhantomJS;无界面的浏览器,它会把网站加载到内存并执行页面上的 JavaScript，因为不会展示图形界面，所以运行起来比完整的浏览器要高效。</span><br><span class="line">WebDriver :WebDriver 有点儿像可以加载网站的浏览器，但是它也可以像 BeautifulSoup 或者其他 Selector 对象一样用来查找页面元素，</span><br><span class="line">        与页面上的元素进行交互 (发送文本、点击等)，以及执行其他动作来运行网络爬虫。</span><br><span class="line"></span><br><span class="line">    理念:所见即所得</span><br><span class="line">    browser---selenium(自动化测试工具) phantomsjs</span><br><span class="line">    selenium 安装;</span><br><span class="line">        pip install selenium</span><br><span class="line">    phantomsjs安装:</span><br><span class="line">        解压</span><br><span class="line">        配置环境变量:</span><br><span class="line">        系统变量Path : bin目录</span><br><span class="line"></span><br><span class="line">     按键精灵 ---自动打怪:提供很多鼠标和键盘的API接口</span><br><span class="line"></span><br><span class="line">#导入webdriver</span><br><span class="line">#from selenium import webdriver</span><br><span class="line">    browser.webdriver.PhantomJS()  #调用环境变量指定的phantomJS浏览器创建浏览对象</span><br><span class="line">    browser.get(&apos;网页地址&apos;)</span><br><span class="line">    time.sleep(1)   请求1秒</span><br><span class="line">    print(browser.page_source)  输出爬到的页面</span><br><span class="line">    # key是要传入的参数 by_name;可以根据name属性查找</span><br><span class="line">    browser.find_element_by_id(&apos;kw&apos;).send_keys(&apos;双十一&apos;)   根据id找到相应标签,传入要搜素的内容</span><br><span class="line">    browser.save_screenshot(&apos;baidu.png&apos;) 查看浏览器状态,截图显示;</span><br><span class="line">    browser.find_element_by_id(&apos;su&apos;).click()  找到百度知道,然后点击</span><br><span class="line">    browser.execute_script()  执行js代码</span><br><span class="line">    time.sleep(1)</span><br><span class="line">查找类:</span><br><span class="line">    BeautifulSoup 取数据时候: 属性id # ; 属性class .</span><br><span class="line">    span[class*=&quot;tag ellipsis&quot;][0].text 取span下的复合class的值;</span><br><span class="line"></span><br><span class="line">mysql数据库:</span><br><span class="line">    1.连接数据库         conn = pymysql.connect(ip,账号,密码,库,编码)</span><br><span class="line">    2.创建数据库操作对象</span><br><span class="line">    3.构建sql语句</span><br><span class="line">    4.执行sql语句  sql = &apos;select version()&apos;</span><br><span class="line">    5.获取执行结果</span><br><span class="line">        增删改:影响行数</span><br><span class="line">        查询:获取结果集</span><br><span class="line"></span><br><span class="line">    增删改操作需要提交;</span><br><span class="line">    conn.commit()  提交事物;</span><br><span class="line">    mydb.exe(sql) 执行语句</span><br></pre></td></tr></table></figure></p>
<p>##day 5:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">    php集成开发环境里面有mysql:lnmp lamp negix</span><br><span class="line">	selenium包的webdriver 自动化获取;</span><br><span class="line"></span><br><span class="line">百度图片瀑布流:</span><br><span class="line">    document.body.scrollHeight  页面高度;</span><br><span class="line">    scrollTo(0,document.body.scrollHeight)  页面滚动到底部;</span><br><span class="line">    scrollTo(0,0)  页面滚动到顶部;</span><br><span class="line"></span><br><span class="line">    browser.execute_script()  执行js代码</span><br><span class="line"></span><br><span class="line">XPATH:</span><br><span class="line">from lxml import etree:   导入包,使用的是直接找div的方法</span><br><span class="line">    ./image/@src  获取图片的src属性; xpath</span><br><span class="line">    在scrapy中使用xpath要在末尾加 .extract()</span><br><span class="line"></span><br><span class="line">CSS选择器:</span><br><span class="line">    name = teacher.css(&apos;h1::text&apos;).extract()[0] 获取文本</span><br><span class="line">    image = teacher.css(&apos;img::attr(src)&apos;).extract()[0]</span><br><span class="line"></span><br><span class="line">报错原因:</span><br><span class="line">    10061:网络问题</span><br><span class="line">    403 For:服务器拒绝访问</span><br><span class="line"></span><br><span class="line">    scrapy Engine(引擎):负责Spider,ItemPipeline,Downloader,Scheduler中间的通讯,信号,数据传递等</span><br><span class="line">    Scheduler(调度器):负责搜素引擎发送过来的Request请求,并按照一定的方式进行整理队列,入队(Queue),当引擎需要时,交换给引擎</span><br><span class="line">    Downloader(下载器):负责下载scrapy Engine(引擎)发送的Request请求,并且将获取到的Response,交换给引擎,由引擎交给Spider来处理</span><br><span class="line">    Spider(爬虫):它负责处理所以Response,从中分析提取数据,获取item字段需要的数据,并将需要跟进的URL提交给引擎,再进入Scheduler调度器</span><br><span class="line">    Item Pipeline(管道):它负责处理Spider中获取item,并且进行后期处理(详细分析,过滤,存储)</span><br><span class="line">    Downloader Middlewares(下载中间件):自定义扩展功能的组件</span><br><span class="line">    Spider Middlewares(Spider中间件):中间通信</span><br><span class="line">    Item: 定义爬取的字段;</span><br><span class="line"></span><br><span class="line">爬虫四步骤:&apos;</span><br><span class="line">    创建一个新的爬虫项目(Scrapy startproject xxx)</span><br><span class="line">    明确你要爬取的目标 (编写items.py)</span><br><span class="line">    制作爬虫开始爬取网页: spiders/xxspider.py</span><br><span class="line">    设计管道存储爬取内容: pipelines.py</span><br><span class="line"></span><br><span class="line"> 爬取时加参数-o: scrapy crawl xdl -o teacher.json</span><br><span class="line"></span><br><span class="line">关于爬虫的建议:</span><br><span class="line">    尽量减少请求次数,能抓列表页不抓详情页,减轻服务器压力;</span><br><span class="line">    反爬手段可以适用web,手机App和H5</span><br><span class="line">    尽量少用ip去做防守</span><br><span class="line">    要求高性能,可以考虑多线程(Scrapy框架支持),分布式</span><br><span class="line"></span><br><span class="line">加锁, 释放锁;</span><br><span class="line"></span><br><span class="line">python语言的优点;</span><br><span class="line">    优雅,明确,简单</span><br><span class="line">    开发效率高,第三方库强大,降低开发周期,避免重复造车</span><br><span class="line">    高级语言,无需考虑底层实现</span><br><span class="line">    可移植性强,可以在不同平台运行</span><br><span class="line">    可扩展性,可以运用C 或者其他编写,在python中运行</span><br><span class="line">    可嵌入性,可嵌入C/C++,</span><br><span class="line">缺点:</span><br><span class="line">    速度慢,但是对于调试工具而言,用户无法感知</span><br><span class="line">    代码不能加密,因为是解释性语言,代码明文存在</span><br><span class="line"></span><br><span class="line">python中的程序分析包,可以检测程序的运行速度: cProfile</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Request:url地址，方法，headers,cookie</p>
</blockquote>
<p>##day3:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">反爬虫手段:</span><br><span class="line">    urllib User-Agent 随机的选择浏览器身份 ;</span><br><span class="line">    proxy 随机挑选代理发起请求代理 ;</span><br><span class="line">    timeout timesleep; 验证码; Pathtomjs selenium;</span><br><span class="line"></span><br><span class="line">如何导入setting配置:</span><br><span class="line">    如何导入settings 配置</span><br><span class="line">    1.</span><br><span class="line">    from py03_spider_day13 import settings</span><br><span class="line">    settings.USER_AGENTS</span><br><span class="line">    2.</span><br><span class="line">    from scrapy.conf import settings</span><br><span class="line">    settings[&apos;USER_AGENTS&apos;]</span><br><span class="line">    3.</span><br><span class="line">    @classmethod</span><br><span class="line">    def from_crawler(cls,crawler):</span><br><span class="line">        return cls(crawler)</span><br><span class="line"></span><br><span class="line">管理user-agent的包:fake-useragent</span><br><span class="line">    ua.random  随机 user-agent;</span><br><span class="line"></span><br><span class="line">一个中间件就是一个类,静态方法先加载</span><br><span class="line">__init__()方法是一种特殊的方法,被称为类的构造函数或初始化方法,当创建这个类的实例时调用该方法</span><br><span class="line"></span><br><span class="line">redis:缓存型数据库,数据存在内存中</span><br><span class="line">    1.指纹识别机制</span><br><span class="line">    2.统一管理请求队列</span><br><span class="line">    3.爬取数据统一管理</span><br><span class="line"></span><br><span class="line">Scrapy框架:</span><br><span class="line"></span><br><span class="line">     进入：(win)Scripts\activate</span><br><span class="line">	       (linux)source activate</span><br><span class="line">     scrapy startproject scrpy_test 创建项目</span><br><span class="line">     scrapy genspider baidu www.baidu.com   需要进入项目目录</span><br><span class="line">     scrapy genspider -t crawl baidu www.baidu.com</span><br><span class="line">     scrapy crawl baidu      启动项目</span><br><span class="line"></span><br><span class="line">     split 以指定字符切割字符串 转换成列表</span><br><span class="line">     strip() 方法用于移除字符串头尾指定的字符（默认为空格）转换后成列表</span><br><span class="line">     replace() 方法把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max</span><br><span class="line">	 strip() 去掉空格;</span><br><span class="line">     replace(&apos;万&apos;,&apos;&apos;)  去掉万;</span><br><span class="line"></span><br><span class="line">打开redis方法:</span><br><span class="line">在setting文件中配置:</span><br><span class="line">  </span><br><span class="line">    Linux:</span><br><span class="line">        cd redis</span><br><span class="line">        cd src</span><br><span class="line">        ./redis-server /etc/redis.conf</span><br><span class="line"></span><br><span class="line">    window:</span><br><span class="line">		redis-server.exe redis.windows.conf</span><br><span class="line">        redis-cli -h 192.168.103.110</span><br><span class="line">        lpush liepinspider:urls https://www.liepin.com</span><br><span class="line">        keys *</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/scrapy/" rel="tag"># scrapy</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/11/26/hello-world/" rel="next" title="Hello World">
                <i class="fa fa-chevron-left"></i> Hello World
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/11/27/name/" rel="prev" title="name">
                name <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">李丛丛</p>
              <p class="site-description motion-element" itemprop="description">欲带皇冠,必承其重</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">分类</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
              
                <span class="links-of-author-item">
                  <a href="https://github.com/acuteli" target="_blank" title="GitHub">
                    
                      <i class="fa fa-fw fa-globe"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:congzhouli@163.com" target="_blank" title="E-Mail">
                    
                      <i class="fa fa-fw fa-globe"></i>E-Mail</a>
                </span>
              
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#爬虫"><span class="nav-number">1.</span> <span class="nav-text">爬虫</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python中操作文件步骤"><span class="nav-number"></span> <span class="nav-text">python中操作文件步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#计算机操作系统分为-硬件-操作系统-应用程序"><span class="nav-number">1.</span> <span class="nav-text">计算机操作系统分为:硬件,操作系统,应用程序</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HTTP"><span class="nav-number">2.</span> <span class="nav-text">HTTP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HTTP工作流程"><span class="nav-number">3.</span> <span class="nav-text">HTTP工作流程:</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#计算10天前是几号"><span class="nav-number">4.</span> <span class="nav-text">计算10天前是几号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网络爬虫的原理-网络请求-抓取结构化数据-数据存储"><span class="nav-number">5.</span> <span class="nav-text">网络爬虫的原理 网络请求 抓取结构化数据 数据存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集合"><span class="nav-number">6.</span> <span class="nav-text">集合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Apache和Tomcat比较"><span class="nav-number">7.</span> <span class="nav-text">Apache和Tomcat比较</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网页爬虫的基本工作原理"><span class="nav-number">8.</span> <span class="nav-text">网页爬虫的基本工作原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#用于转化header"><span class="nav-number">9.</span> <span class="nav-text">用于转化header</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#积累"><span class="nav-number">10.</span> <span class="nav-text">积累</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cookie"><span class="nav-number">11.</span> <span class="nav-text">cookie</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#第四天-正则表达式"><span class="nav-number"></span> <span class="nav-text">第四天  正则表达式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#day5-反反爬"><span class="nav-number"></span> <span class="nav-text">day5:反反爬</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#周一-如何解析页面-提取数据"><span class="nav-number">1.</span> <span class="nav-text">周一: 如何解析页面,提取数据</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">李丛丛</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
